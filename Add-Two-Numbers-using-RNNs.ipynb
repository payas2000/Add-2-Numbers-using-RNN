{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Dropout, SimpleRNN, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Data \n",
    "all_chars = '0123456789+' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features :  11\n"
     ]
    }
   ],
   "source": [
    "num_features = len(all_chars)\n",
    "print('Number of features : ', num_features)\n",
    "char_to_index = dict((c, i) for i, c in enumerate(all_chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(all_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('36+96', '132')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data():\n",
    "    first = np.random.randint(0, 100)\n",
    "    second = np.random.randint(0,100)\n",
    "    example = str(first) + '+' + str(second)\n",
    "    label = str(first + second)\n",
    "    return example, label\n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focused-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 128)               17920     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 5, 128)            32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 11)             1419      \n",
      "=================================================================\n",
      "Total params: 52,235\n",
      "Trainable params: 52,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create the Model\n",
    "hidden_units = 128\n",
    "max_time_steps = 5\n",
    "\n",
    "model = Sequential([\n",
    "    #encoder\n",
    "    SimpleRNN(hidden_units, input_shape = (None, num_features)), \n",
    "    RepeatVector(max_time_steps), \n",
    "    #decoder\n",
    "    SimpleRNN(hidden_units, return_sequences = True),\n",
    "    TimeDistributed(Dense(num_features, activation = 'softmax'))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy', \n",
    "    optimizer = 'adam', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appreciated-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18+67 85\n",
      "(5, 11) (5, 11)\n"
     ]
    }
   ],
   "source": [
    "#Vectorize and De-Vectorize the Data \n",
    "def vectorize_example(example, label):\n",
    "    x = np.zeros((max_time_steps, num_features))\n",
    "    y = np.zeros((max_time_steps, num_features))\n",
    "    \n",
    "    diff_x = max_time_steps - len(example)\n",
    "    diff_y = max_time_steps - len(label)    \n",
    "    \n",
    "    for i, c in enumerate(example):\n",
    "        x[i+diff_x, char_to_index[c]] = 1\n",
    "    for i in range(diff_x):\n",
    "        x[i, char_to_index['0']] = 1\n",
    "        \n",
    "    for i, c in enumerate(label):\n",
    "        y[i+diff_y, char_to_index[c]] = 1\n",
    "    for i in range(diff_y):\n",
    "        y[i, char_to_index['0']] = 1\n",
    "    return x, y\n",
    "\n",
    "e, l = generate_data()\n",
    "print(e, l)\n",
    "x, y = vectorize_example(e, l)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thrown-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18+67'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def devectorize_example(example):\n",
    "        result = [index_to_char[np.argmax(vec)] for i, vec in enumerate(example)]\n",
    "        return ''.join(result)\n",
    "    \n",
    "devectorize_example(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "signed-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00085'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devectorize_example(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "random-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5, 11) (20000, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "#Create Dataset\n",
    "def create_dataset(num_examples=2000):\n",
    "\n",
    "    x_train = np.zeros((num_examples, max_time_steps, num_features))\n",
    "    y_train = np.zeros((num_examples, max_time_steps, num_features))\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        e, l = generate_data()\n",
    "        x, y = vectorize_example(e, l)\n",
    "        x_train[i] = x\n",
    "        y_train[i] = y\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = create_dataset(20000)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "printable-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83+98'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devectorize_example(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "damaged-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00181'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devectorize_example(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "greatest-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61 _ 0.62 _ 0.63 _ 0.64 _ 0.65 _ 0.65 _ 0.67 _ 0.69 _ 0.71 _ 0.74 _ 0.75 _ 0.77 _ 0.78 _ 0.79 _ 0.79 _ 0.80 _ 0.81 _ 0.83 _ 0.85 _ 0.85 _ 0.89 _ 0.91 _ 0.92 _ 0.94 _ 0.95 _ 0.96 _ 0.96 _ 0.97 _ 0.97 _ 0.97 _ 0.98 _ 0.98 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 0.99 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ 1.00 _ "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xbad8617a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the Model\n",
    "simple_logger = LambdaCallback(\n",
    "    on_epoch_end=lambda e, l: print('{:.2f}'.format(l['val_accuracy']), end=' _ ')\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, validation_split=0.2, verbose=False,\n",
    "         batch_size=1024, callbacks=[simple_logger, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unsigned-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInput: 08+52, Out: 00060, Pred: 00060\u001b[0m\n",
      "\u001b[32mInput: 12+94, Out: 00106, Pred: 00106\u001b[0m\n",
      "\u001b[32mInput: 03+55, Out: 00058, Pred: 00058\u001b[0m\n",
      "\u001b[32mInput: 96+27, Out: 00123, Pred: 00123\u001b[0m\n",
      "\u001b[32mInput: 28+47, Out: 00075, Pred: 00075\u001b[0m\n",
      "\u001b[32mInput: 19+95, Out: 00114, Pred: 00114\u001b[0m\n",
      "\u001b[32mInput: 60+96, Out: 00156, Pred: 00156\u001b[0m\n",
      "\u001b[32mInput: 54+83, Out: 00137, Pred: 00137\u001b[0m\n",
      "\u001b[32mInput: 79+46, Out: 00125, Pred: 00125\u001b[0m\n",
      "\u001b[32mInput: 70+35, Out: 00105, Pred: 00105\u001b[0m\n",
      "\u001b[32mInput: 79+72, Out: 00151, Pred: 00151\u001b[0m\n",
      "\u001b[32mInput: 21+90, Out: 00111, Pred: 00111\u001b[0m\n",
      "\u001b[32mInput: 18+44, Out: 00062, Pred: 00062\u001b[0m\n",
      "\u001b[32mInput: 67+24, Out: 00091, Pred: 00091\u001b[0m\n",
      "\u001b[32mInput: 65+64, Out: 00129, Pred: 00129\u001b[0m\n",
      "\u001b[32mInput: 13+91, Out: 00104, Pred: 00104\u001b[0m\n",
      "\u001b[32mInput: 16+54, Out: 00070, Pred: 00070\u001b[0m\n",
      "\u001b[32mInput: 025+2, Out: 00027, Pred: 00027\u001b[0m\n",
      "\u001b[32mInput: 010+4, Out: 00014, Pred: 00014\u001b[0m\n",
      "\u001b[32mInput: 33+26, Out: 00059, Pred: 00059\u001b[0m\n",
      "\n",
      "Full sequence accuracy: 100.000 %\n"
     ]
    }
   ],
   "source": [
    "#Create a test set and look at some predictions\n",
    "x_test, y_test = create_dataset(num_examples=20)\n",
    "preds = model.predict(x_test)\n",
    "full_seq_acc = 0\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    pred_str = devectorize_example(pred)\n",
    "    y_test_str = devectorize_example(y_test[i])\n",
    "    x_test_str = devectorize_example(x_test[i])\n",
    "    col = 'green' if pred_str == y_test_str else 'red'\n",
    "    full_seq_acc += 1/len(preds) * int(pred_str == y_test_str)\n",
    "    outstring = 'Input: {}, Out: {}, Pred: {}'.format(x_test_str, y_test_str, pred_str)\n",
    "    print(colored(outstring, col))\n",
    "print('\\nFull sequence accuracy: {:.3f} %'.format(100 * full_seq_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
